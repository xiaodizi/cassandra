== Second Index ES 二级索引到
二级索引是单独建立一个索引表，将索引数据存入其他位置，在cassandra自己本身实现了SASI,也是实现了二级索引的一种形式。

V4.1.2.4 分支实现的是将索引数据存入Opensearch或者Elasticsearch。

== 索引原理说明
举例：在Cassandra中存储了这么一张车辆信息表
image:doc/img/3.png[]

如果单纯里边关系型数据库，查询主键，在大数据量的情况下，这种性能影响不大。
索引大数量情况下的索引成了问题的关键，比如，希望查询车牌号的情况下，如果车牌号，就需要为车牌号这个字段增加索引才可以。

在这种情况下，就可以利用一下倒排索引的做法，避免全表扫描。
所以索引写入opensearch或者elasticsearch就整合优势，cassandra作为了宽表的存储，es进行索引查询。
二级索引写入之后，假如要查询车辆品牌为`宝马`的车辆数据提前的倒排索引会是如下这个样子：

image:doc/img/4.png[]

可以快速定位到有相关数据的位置。


== 还需要做的事情

1、目前还不知道多条件的组合查询，需要增加bool查询的支持。
2、同步过去的数据，目前还不支持子字段。
3、在cql客户端尝试增加es的聚合结果支持。

== 如何使用
=== 1、Cql客户端 数据写入
==== 首先创建一个keyspace。
-----
CREATE KEYSPACE demo
WITH REPLICATION = {'class': 'SimpleStrategy', 'replication_factor': 1};
-----

==== 再创建一张表，在这个keyspace
----
CREATE TABLE demo.tweets (
   id INT PRIMARY KEY,
   user TEXT,
   body TEXT,
   time TIMESTAMP,
   latitude FLOAT,
   longitude FLOAT
);
----
==== 创建表只需要加一个 PRIMARY KEY 主键就可以了，比如复合主键这种就不需要了，也会造成一些其他问题。

==== 创建二级索引
----
CREATE CUSTOM INDEX tweets_index ON demo.tweets ()
USING 'org.apache.second.ElasticSecondaryIndex'
WITH OPTIONS = {
   'refresh_seconds': '10',
   'schema': '{
      fields: {
         id: {type: "integer"},
         user: {type: "text"},
         body: {type: "text", analyzer: "english"},
         time: {type: "date", pattern: "yyyy-MM-dd"},
         latitude: {type: "float"},
         longitude: {type:"float"}
      }
   }'
};
----
==== 这是一个典型的全表索引的例子，`schema` 里是配置的是索引到Opensearch或者Elasticsearch的字段，要注意 `type` 里边的字段类型，这个需要严格遵守Elasticsearch里的字段类型。
==== `refresh_sconds` 是配置Elasticsearch 或者Opensearch 里的 刷新频率。如果在数据量大的情况下，这个配置的调整我个人认为还是很有必要的。

==== 再说明一点，目前配置，只支持自定义字段类型和自定义分词器。


==== 这时候，就可以看到，在 Opensearch 或者 ES 里创建了索引，这时候还没有数据。创建的索引是  `keyspace名字.table名字` 这种形式。
举例上边的表，可以使用如下进行在ES或者Opensearch中查询
----
GET demo.tweets/_search
----
应该返回如下结果：
----
{
  "took": 2,
  "timed_out": false,
  "_shards": {
    "total": 1,
    "successful": 1,
    "skipped": 0,
    "failed": 0
  },
  "hits": {
    "total": {
      "value": 0,
      "relation": "eq"
    },
    "max_score": null,
    "hits": []
  }
}
----

==== 接下来可以尝试写入几条数据
----
INSERT INTO demo.tweets (id, user, body, time,latitude,longitude) VALUES (1, 'fu', '123456', '2015-05-15',41.12,-71.34);

INSERT INTO demo.tweets (id, user, body, time,latitude,longitude) VALUES (2, 'fu', '123456', '2019-05-15',41.12,-71.34);

INSERT INTO demo.tweets (id, user, body, time,latitude,longitude) VALUES (3, 'lei', '123456', '2019-05-15',41.12,-71.34);
----

Cassandra 查询的数据是如下样子的：
----
cqlsh> select * from demo.tweets;

 id | body   | latitude | longitude | time                            | user
----+--------+----------+-----------+---------------------------------+------
  1 | 123456 |    41.12 |    -71.34 | 2015-05-14 16:00:00.000000+0000 |   fu
  2 | 123456 |    41.12 |    -71.34 | 2019-05-14 16:00:00.000000+0000 |   fu
  3 | 123456 |    41.12 |    -71.34 | 2019-05-14 16:00:00.000000+0000 |  lei

(3 rows)
cqlsh>
----

Opensearch或者Elasticsearch里边查询到的数据是如下样子的：
----
{
  "took": 16,
  "timed_out": false,
  "_shards": {
    "total": 1,
    "successful": 1,
    "skipped": 0,
    "failed": 0
  },
  "hits": {
    "total": {
      "value": 3,
      "relation": "eq"
    },
    "max_score": 1,
    "hits": [
      {
        "_index": "demo.tweets",
        "_id": "2",
        "_score": 1,
        "_source": {
          "latitude": 41.12,
          "id": "2",
          "time": "2019-05-15",
          "body": "123456",
          "user": "fu",
          "longitude": -71.34
        }
      },
      {
        "_index": "demo.tweets",
        "_id": "1",
        "_score": 1,
        "_source": {
          "latitude": 41.12,
          "id": "1",
          "time": "2015-05-15",
          "body": "123456",
          "user": "fu",
          "longitude": -71.34
        }
      },
      {
        "_index": "demo.tweets",
        "_id": "3",
        "_score": 1,
        "_source": {
          "latitude": 41.12,
          "id": "3",
          "time": "2019-05-15",
          "body": "123456",
          "user": "lei",
          "longitude": -71.34
        }
      }
    ]
  }
}
----

==== 三条数据，可以进行对比一下，效果。


=== 2、ycsb 写入数据

ycsb是个cassandra的测试工具，以下是为了测试准备的keyspace、表和索引。
----
create keyspace ycsb
    WITH REPLICATION = {'class' : 'SimpleStrategy', 'replication_factor': 1 };


create table ycsb.usertable (
y_id varchar primary key,
field0 text,
field1 text,
field2 text,
field3 text,
field4 text,
field5 text,
field6 text,
field7 text,
field8 text,
field9 text);


CREATE CUSTOM INDEX usertable_index ON ycsb.usertable ()
USING 'org.apache.second.ElasticSecondaryIndex'
WITH OPTIONS = {
   'refresh_seconds': '1',
   'schema': '{
      fields: {
         field0: {type: "text"},
         field1: {type: "text"},
         field2: {type: "text"},
         field3: {type: "text"},
         field4: {type: "text"},
         field5: {type: "text"},
         field6: {type: "text"},
         field7: {type: "text"},
         field8: {type: "text"},
         field9: {type: "text"}
      }
   }'
};
----

以下是测试结果：
----
2023-06-28 10:57:55:488 10 sec: 8726 operations; 872.16 current ops/sec; est completion in 2 second [INSERT: Count=8728, Max=280831, Min=1460, Avg=53657.9, 90=102847, 99=192511, 99.9=274943, 99.99=280575]
2023-06-28 10:58:00:211 14 sec: 10000 operations; 269.74 current ops/sec; [CLEANUP: Count=50, Max=2238463, Min=0, Avg=44751.6, 90=4, 99=2238463, 99.9=2238463, 99.99=2238463] [INSERT: Count=1272, Max=242303, Min=1999, Avg=69652.12, 90=127103, 99=204159, 99.9=236287, 99.99=242303]
[OVERALL], RunTime(ms), 14728
[OVERALL], Throughput(ops/sec), 678.9788158609451
[TOTAL_GCS_G1_Young_Generation], Count, 3
[TOTAL_GC_TIME_G1_Young_Generation], Time(ms), 15
[TOTAL_GC_TIME_%_G1_Young_Generation], Time(%), 0.10184682237914178
[TOTAL_GCS_G1_Old_Generation], Count, 0
[TOTAL_GC_TIME_G1_Old_Generation], Time(ms), 0
[TOTAL_GC_TIME_%_G1_Old_Generation], Time(%), 0.0
[TOTAL_GCs], Count, 3
[TOTAL_GC_TIME], Time(ms), 15
[TOTAL_GC_TIME_%], Time(%), 0.10184682237914178
[CLEANUP], Operations, 50
[CLEANUP], AverageLatency(us), 44751.6
[CLEANUP], MinLatency(us), 0
[CLEANUP], MaxLatency(us), 2238463
[CLEANUP], 95thPercentileLatency(us), 18
[CLEANUP], 99thPercentileLatency(us), 2238463
[INSERT], Operations, 10000
[INSERT], AverageLatency(us), 55692.3614
[INSERT], MinLatency(us), 1460
[INSERT], MaxLatency(us), 280831
[INSERT], 95thPercentileLatency(us), 130367
[INSERT], 99thPercentileLatency(us), 194431
[INSERT], Return=OK, 10000
----

一万条随机生成的数据，写入cassandra大概在14秒。但是同步到Opensearch或者Elasticsearch，就不一定了。ES有refresh机制，就算写入了，也得看`refresh_seconds`的设置，时间越大看到的时间越长。
目前看对cassandra的性能不会造成影响。



=== 3、查询
起初的想法是希望lucene的原始语法做查询，但是Elasticsearch本身还是对lucene的一些语法做了调整的，所以就按照Elasticsearch的DSL语法进行兼容了。
==== 1、range查询
可以看如下cql语句：
----
<!--range查询-->
SELECT * FROM demo.tweets WHERE expr(tweets_index, '{
   query: {type: "range", field: "time", gte: "2014-04-25", lte: "2015-05-21"}
}');
----
----
query:代表的就是普通查询
type:代表的就是DSL的查询函数
field: 代表的是要查询的字段
gte:  大于等于
lte:  小于等于
----

==== 2、match 查询
----
<!--match查询-->
SELECT * FROM demo.tweets WHERE expr(tweets_index, '{
   query: {type: "match", field: "user", query: "lei"}
}');
----
这里边就是修改了type为match，在query的子字段里边增加了query，代表了要查询的值。

==== 3、match 查询 value 形式写法。
----
<!--match查询, value形式-->
SELECT * FROM demo.tweets WHERE expr(tweets_index, '{
   query: {type: "match", field: "user", value: "lei"}
}');
----
跟上边的写法，其实效果是一样的，就是把query写成了value。主要做这两种，是考虑以后增加boost的评分机制。

==== 4、match_phrase 查询
----
<!--match_phrase查询-->
SELECT * FROM demo.tweets WHERE expr(tweets_index, '{
   query: {type: "match_phrase", field: "user", query: "lei"}
}');
----
不多解释了，同match查询。

==== 5、match_phrase查询, value形式
----
<!--match_phrase查询, value形式-->
SELECT * FROM demo.tweets WHERE expr(tweets_index, '{
   query: {type: "match_phrase", field: "user", value: "lei"}
}');
----
不多解释了，同match查询。

==== 6、term 查询
----
<!--term查询 -->
SELECT * FROM demo.tweets WHERE expr(tweets_index, '{
   query: {type: "term", field: "user", value: "lei"}
}');
----
不多解释了，同match查询。

==== 7、强制刷新
----
<!--强制刷新后，range查询-->
SELECT * FROM demo.tweets WHERE expr(tweets_index, '{
   query: {type: "range", field: "time", gte: "2014-04-25", lte: "2015-05-21"},
   refresh: true
}') limit 100;
----
在查询的时候，增加了refresh这个配置，如果为true，会强制进行刷新索引。





